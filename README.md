### Edge-Vision: TinyML-Powered Anomaly Detection
https://img.shields.io/badge/TinyML-Edge%2520Computing-blue
https://img.shields.io/badge/Privacy-Preserving-green
https://img.shields.io/badge/Python-3.8%252B-yellow
https://img.shields.io/badge/License-Apache%25202.0-orange
Edge-Vision: TinyML-Powered Anomaly Detection

âš¡ On-device anomaly detection â€” Deploying efficient, privacy-preserving computer vision models for smart infrastructure, IoT, and Industry 4.0 applications.

ğŸŒ Background & Motivation
Modern urban environments and industrial facilities generate enormous volumes of visual data through distributed IoT sensors and CCTV networks. Traditional cloud-based processing approaches face significant challenges:
âŒ High latency impedes real-time response capabilities

âŒ Substantial bandwidth consumption creates network bottlenecks

âŒ Energy-intensive processing contradicts sustainability goals

âŒ Privacy vulnerabilities from transmitting sensitive visual data

Our solution: Leverage TinyML to perform intelligent anomaly detection directly on edge devices, enabling:
âœ… Real-time inference with minimal latency

âœ… Significant bandwidth and energy conservation

âœ… Enhanced privacy through on-device data processing

âœ… Reduced operational costs for large-scale deployments

This project implements a highly optimized, quantized convolutional neural network distilled from a vision transformer backbone, deployable on resource-constrained hardware (Jetson Nano, Coral TPU, Raspberry Pi). The system detects anomaliesâ€”from manufacturing defects to security incidentsâ€”while preserving privacy through integrated on-device blurring of sensitive regions.

âœ¨ Key Features :

ğŸ“Š Standardized Benchmarking: Utilizes the MVTec-AD dataset for industrial anomaly detection

ğŸ§  Advanced Architectures: Implements and compares AutoEncoder (AE), PatchCore, and SimCLR approaches

ğŸ”„ Model Compression: Employs knowledge distillation from large transformer to compact CNN

ğŸ“‰ Hardware Optimization: Applies quantization-aware training and pruning for edge deployment

ğŸ”’ Privacy by Design: Integrates on-device sensitive region blurring before inference

âš¡ Performance Analysis: Comprehensive evaluation of FPS/latency vs. accuracy vs. energy consumption

ğŸ¥ Real-time Demonstration: Complete pipeline showcasing live anomaly detection with visual overlays

Project Structure :
edge_vision_anomaly_detection/
â”‚
â”œâ”€â”€ data/                           # Dataset and sample assets
â”‚   â”œâ”€â”€ mvtec/                      # MVTec-AD dataset (optional)
â”‚   â””â”€â”€ sample_video.mp4            # Demonstration video
â”‚
â”œâ”€â”€ models/                         # Model definitions and weights
â”‚   â”œâ”€â”€ baseline_ae.pth             # Autoencoder baseline
â”‚   â”œâ”€â”€ distilled_cnn.pth           # Distilled compact model
â”‚   â””â”€â”€ quantized_cnn.tflite        # Quantized model for deployment
â”‚
â”œâ”€â”€ results/                        # Output directory
â”‚   â”œâ”€â”€ training_metrics/           # Training logs and metrics
â”‚   â”œâ”€â”€ performance/                # Hardware performance results
â”‚   â”‚   â”œâ”€â”€ accuracy_vs_latency.png
â”‚   â”‚   â”œâ”€â”€ energy_profile.png
â”‚   â”‚   â””â”€â”€ hardware_benchmark.csv
â”‚   â””â”€â”€ demonstrations/             # Inference examples
â”‚       â””â”€â”€ anomaly_detection_demo.mp4
â”‚
â”œâ”€â”€ src/                            # Source code
â”‚   â”œâ”€â”€ data_processing/            # Data utilities
â”‚   â”‚   â”œâ”€â”€ mvtec_dataset.py        # MVTec-AD dataset handler
â”‚   â”‚   â””â”€â”€ privacy_preprocessor.py # Privacy preservation modules
â”‚   â”œâ”€â”€ models/                     # Model architectures
â”‚   â”‚   â”œâ”€â”€ autoencoder.py          # AE implementation
â”‚   â”‚   â”œâ”€â”€ patchcore.py            # PatchCore implementation
â”‚   â”‚   â””â”€â”€ knowledge_distillation.py # Distillation training
â”‚   â”œâ”€â”€ training/                   # Training routines
â”‚   â”‚   â””â”€â”€ train_utils.py          # Training utilities
â”‚   â”œâ”€â”€ evaluation/                 # Evaluation metrics
â”‚   â”‚   â””â”€â”€ eval_mvtec.py           # MVTec evaluation protocol
â”‚   â”œâ”€â”€ inference/                  # Deployment modules
â”‚   â”‚   â”œâ”€â”€ edge_inferencer.py      # Hardware-specific inference
â”‚   â”‚   â””â”€â”€ anomaly_visualizer.py   # Visualization utilities
â”‚   â”œâ”€â”€ utils/                      # Helper functions
â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”‚   â””â”€â”€ logger.py               # Logging utilities
â”‚   â”œâ”€â”€ main.py                     # Main training/evaluation script
â”‚   â””â”€â”€ demo.py                     # Demonstration pipeline
â”‚
â”œâ”€â”€ tests/                          # Unit tests
â”œâ”€â”€ docs/                           # Additional documentation
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ environment.yml                 # Conda environment setup
â””â”€â”€ README.md                       # This document

âš™ï¸ Installation & Setup
Option 1: Pip Installation 
# Clone repository
git clone https://github.com/srizoni-maity/Edge-Vision-Anomaly-Detection-with-TinyML-Privacy-Preserving-AI-for-Smart-Cities-IoT
cd edge_vision_anomaly_detection

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # Linux/MacOS
# or
.\venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt

Option 2: Conda Installation
# Create conda environment
conda env create -f environment.yml
conda activate edge-vision

Hardware-Specific Setup
For deployment on specific edge devices, additional setup may be required:

NVIDIA Jetson Nano:
# Install JetPack components
sudo apt-get install python3-pip libopenblas-base libopenmpi-dev
pip install --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v50 tensorflow-gpu
Coral TPU:
# Install Edge TPU runtime
sudo apt-get install edgetpu-compiler python3-pycoral
ğŸš€ Usage Examples

Quick Start with Synthetic Data :
# Train a compact autoencoder on synthetic data
python src/main.py --mode quick_train --epochs 30 --output_dir results/quick_run

# Evaluate model performance
python src/main.py --mode evaluate --model_path results/quick_run/tiny_ae.pth

Generate Demonstration Video :
# Create sample video with synthetic anomalies
python src/utils/create_sample_video.py --output data/sample_video.mp4

# Run inference on sample video
python src/demo.py --video data/sample_video.mp4 --model models/quantized_cnn.tflite --output results/demo_output.mp4

Full Training on MVTec-AD (Requires Dataset)
# Train on specific MVTec category
python src/main.py --mode train --dataset_path data/mvtec --category bottle --epochs 100 --batch_size 32

# Knowledge distillation from teacher to student model
python src/training/knowledge_distillation.py --teacher models/patchcore.pth --student models/tiny_cnn.pth --dataset data/mvtec/hazelnut

Hardware Benchmarking :
# Benchmark model on available hardware
python src/inference/edge_inferencer.py --model models/quantized_cnn.tflite --benchmark --runs 1000

# Compare energy consumption across devices
python src/utils/energy_profiler.py --model models/quantized_cnn.tflite --duration 60
ğŸ“Š Performance Results
Our optimized models achieve compelling performance trade-offs:

Model	Size (MB)	Accuracy (AUC)	Latency (ms)	Energy (mJ/inf)
Baseline AutoEncoder	18.2	0.87	42.3	125.6
Distilled CNN	4.7	0.85	18.7	63.2
Quantized CNN (INT8)	1.2	0.83	8.4	28.9
*Results measured on Jetson Nano 4GB with MVTec-AD bottle category*

https://results/performance/accuracy_vs_latency.png
Trade-off between detection accuracy and inference latency


ğŸŒ Application Scenarios
ğŸ­ Smart Manufacturing
Real-time defect detection on production lines without cloud dependency, enabling immediate quality control interventions.

ğŸ™ï¸ Urban Surveillance
Privacy-aware monitoring of public spaces with local processing that only transmits alerts rather than continuous footage.

ğŸ¥ Healthcare IoT
On-device analysis of medical imaging streams while maintaining strict patient privacy through localized processing.

ğŸ”’ Privacy-Sensitive Environments
Edge deployment in settings where data cannot leave the premises due to regulatory or security constraints.

Example Output Visualization
https://results/demonstrations/anomaly_detection_demo.gif
Red-highlighted regions indicate detected anomalies with confidence scores

ğŸ”® Future Enhancements
Hardware Acceleration: Integration with ONNX Runtime and TensorRT for maximum inference speed
Multi-Modal Learning: Fusion of visual data with complementary sensor inputs (thermal, depth, etc.)
Adaptive Learning: Continuous on-device model refinement based on new data patterns
Federated Learning: Privacy-preserving collaborative model improvement across edge devices
Extended Benchmarking: Support for additional anomaly detection datasets and scenarios

ğŸ‘¥ Authors
Srizoni Maity & Baishakhi Sing 
Project Development & Research


ğŸ™ Acknowledgments
We thank the creators of the MVTec-AD dataset for providing a standardized benchmark for anomaly detection research.



